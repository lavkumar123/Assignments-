{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.\n",
        "Hereâ€™s a breakdown of when to use multithreading versus multiprocessing:\n",
        "\n",
        "### When Multithreading is Preferable:\n",
        "1. **I/O-Bound Tasks**: If the application is I/O-bound (e.g., waiting for file reads, database queries, network responses), multithreading is efficient because threads can work while others wait for I/O, reducing idle time.\n",
        "   - **Example**: A web scraper that fetches pages concurrently or a server handling multiple network requests simultaneously.\n",
        "\n",
        "2. **Shared Memory**: If tasks need to share data frequently or use the same memory, multithreading is preferable because threads share the same memory space, eliminating the need for inter-process communication (IPC).\n",
        "   - **Example**: A GUI application that updates the interface based on background tasks; here, threads can update the UI without needing to communicate across processes.\n",
        "\n",
        "3. **Lightweight Concurrency**: Threads are more lightweight than processes, with lower overhead in context switching. For simple, short-lived concurrent tasks, multithreading reduces resource usage.\n",
        "   - **Example**: Handling lightweight background tasks like logging, monitoring, or handling simple tasks in a web server.\n",
        "\n",
        "4. **Scenarios Limited by GIL** (Python-specific): If youâ€™re using Python, multithreading might be limited due to the Global Interpreter Lock (GIL), which restricts CPU-bound tasks. However, for I/O-bound tasks in Python, multithreading still performs well.\n",
        "\n",
        "### When Multiprocessing is Preferable:\n",
        "1. **CPU-Bound Tasks**: For CPU-intensive operations (e.g., data processing, mathematical calculations, machine learning), multiprocessing allows each process to run on a separate CPU core, improving performance by bypassing Python's GIL.\n",
        "   - **Example**: Parallel processing of large datasets in scientific computing or training machine learning models.\n",
        "\n",
        "2. **Isolation and Stability**: Processes run independently with separate memory space, so if one process crashes, it wonâ€™t affect others. Multiprocessing is ideal for tasks that need to be isolated to avoid mutual interference.\n",
        "   - **Example**: An application handling user-submitted code execution (such as in online coding platforms) where isolating each execution is essential to prevent crashes.\n",
        "\n",
        "3. **Independent Workloads**: When tasks donâ€™t need to share data and are self-contained, multiprocessing allows efficient scaling across multiple cores.\n",
        "   - **Example**: Rendering frames of a video in parallel or processing batches of files independently.\n",
        "\n",
        "4. **Memory-Intensive Tasks**: If tasks require substantial memory, multiprocessing can provide separate memory spaces, preventing conflicts and optimizing memory allocation across processes.\n",
        "   - **Example**: A data-processing pipeline with stages that handle memory-heavy transformations.\n",
        "\n",
        "### Summary Table:\n",
        "\n",
        "| Scenario                          | Multithreading                     | Multiprocessing                     |\n",
        "|-----------------------------------|------------------------------------|-------------------------------------|\n",
        "| I/O-bound tasks                   | âœ…                                 | ðŸš«                                  |\n",
        "| CPU-bound tasks                   | ðŸš«                                  | âœ…                                  |\n",
        "| Shared memory requirements        | âœ…                                 | ðŸš«                                  |\n",
        "| Isolation needed                  | ðŸš«                                  | âœ…                                  |\n",
        "| Lightweight concurrency           | âœ…                                 | ðŸš«                                  |\n",
        "| Memory-intensive tasks            | ðŸš«                                  | âœ…                                  |\n",
        "\n",
        "### Conclusion\n",
        "- **Multithreading** is ideal for I/O-bound, shared-memory, lightweight tasks.\n",
        "- **Multiprocessing** suits CPU-bound, isolated, and memory-intensive tasks."
      ],
      "metadata": {
        "id": "qfvaJ13mLyhS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
        "\n",
        "**Ans:-**A **process pool** is a collection of pre-spawned worker processes that can be reused to handle multiple tasks, one at a time. Instead of creating a new process for every single task, a process pool allows you to submit tasks to a pool of worker processes that already exist, making it more efficient for managing concurrent tasks.\n",
        "\n",
        "### Key Features and Benefits of a Process Pool\n",
        "\n",
        "1. **Efficient Process Management**:\n",
        "   - Creating and destroying processes repeatedly incurs significant overhead. A process pool minimizes this by keeping a set of processes ready to perform tasks.\n",
        "   - The pool of worker processes remains available throughout the program's runtime, allowing tasks to be executed without the need to repeatedly initialize or terminate processes.\n",
        "\n",
        "2. **Concurrency Control**:\n",
        "   - The size of the process pool (number of workers) can be specified to limit the number of simultaneous processes. This ensures the system isnâ€™t overloaded by creating too many processes at once, which can slow down performance.\n",
        "   - By managing a fixed number of workers, a process pool efficiently balances the workload across available CPU cores.\n",
        "\n",
        "3. **Automatic Task Distribution**:\n",
        "   - A process pool has a built-in task queue. As tasks are added, they are automatically distributed to available processes in the pool, which execute the tasks concurrently.\n",
        "   - This also simplifies the management of tasks, as tasks are queued, executed, and retrieved without requiring manual process management.\n",
        "\n",
        "4. **Improved Performance for CPU-Bound and I/O-Bound Tasks**:\n",
        "   - For CPU-bound tasks, a process pool allows parallelism across multiple cores by utilizing the workers concurrently.\n",
        "   - For I/O-bound tasks (if supported by the language), the process pool enables asynchronous task handling, reducing idle time when processes are waiting for I/O operations to complete.\n",
        "\n",
        "### How It Works in Practice\n",
        "\n",
        "The process pool pattern typically involves:\n",
        "1. **Creating the Pool**: Define the number of worker processes in the pool, often based on the number of CPU cores available.\n",
        "2. **Submitting Tasks**: Tasks are submitted to the pool, either as a batch or individually. Each worker picks up a task when it becomes free.\n",
        "3. **Execution and Retrieval**: Each process in the pool executes its assigned task, and the results can be retrieved once tasks are complete. In some languages or frameworks, this is managed using functions like `apply()`, `apply_async()`, `map()`, and `map_async()`.\n",
        "\n",
        "### Example Scenario\n",
        "Consider a data-processing task where each worker in the pool handles a part of a large dataset. By using a process pool, we can divide the dataset among multiple processes to run in parallel. The pool ensures efficient load balancing, timely completion, and prevents system overload by restricting the number of concurrent processes.\n",
        "\n",
        "### Example in Python (Using `multiprocessing.Pool`)\n",
        "```python\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def process_data(data_chunk):\n",
        "    # Simulate data processing task\n",
        "    return sum(data_chunk)\n",
        "\n",
        "data = [range(1000000), range(1000000, 2000000), range(2000000, 3000000)]\n",
        "\n",
        "# Create a pool with 4 processes\n",
        "with Pool(4) as pool:\n",
        "    results = pool.map(process_data, data)\n",
        "\n",
        "print(results)  # Output: [sum of each data chunk]\n",
        "```\n",
        "\n",
        "### Summary\n",
        "A process pool helps manage multiple tasks efficiently by reusing a fixed set of worker processes, reducing overhead, improving performance, and simplifying concurrent execution."
      ],
      "metadata": {
        "id": "crexR11nMeO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Explain what multiprocessing is and why it is used in Python programs.\n",
        "**Ans:-** **Multiprocessing** in Python is a module and programming paradigm that enables concurrent execution by creating multiple separate processes, each running independently on separate CPU cores. Each process has its own memory space, allowing it to execute tasks without being constrained by Python's Global Interpreter Lock (GIL), which is a limitation for threads in Python.\n",
        "\n",
        "### Why Multiprocessing is Used in Python Programs\n",
        "\n",
        "1. **Bypassing the Global Interpreter Lock (GIL)**:\n",
        "   - Pythonâ€™s GIL restricts multithreading performance, especially for CPU-bound tasks, by allowing only one thread to execute at a time within a single process. Multiprocessing overcomes this by creating separate processes, each with its own Python interpreter and memory space, so multiple CPU cores can be utilized simultaneously.\n",
        "\n",
        "2. **Parallelism for CPU-Bound Tasks**:\n",
        "   - For tasks that require significant computation (like data processing, scientific calculations, and machine learning), multiprocessing enables parallelism. Each process can handle a portion of the workload, leading to substantial performance gains on multi-core systems.\n",
        "\n",
        "3. **Isolation and Stability**:\n",
        "   - Each process in multiprocessing has its own memory space, which means that issues or crashes in one process do not affect others. This makes multiprocessing more robust for tasks that need to be isolated or are prone to failure.\n",
        "\n",
        "4. **Efficient Task Management**:\n",
        "   - With a structured approach, such as a **process pool**, multiprocessing can manage large workloads by efficiently queuing and distributing tasks among worker processes.\n",
        "\n",
        "### How Multiprocessing Works in Python\n",
        "\n",
        "When using the `multiprocessing` module, you create new processes by:\n",
        "1. **Defining the Task Function**: A function encapsulates the task to be run in each process.\n",
        "2. **Creating Processes**: Each task is assigned to a separate process, either individually or through a process pool.\n",
        "3. **Starting and Joining Processes**: Processes are started to execute their tasks in parallel, and you may wait for them to complete by joining them.\n",
        "\n",
        "### Example Use Case\n",
        "\n",
        "Imagine you have a list of large numbers that need to be squared. With multiprocessing, you can split this list and let each process compute squares of numbers in its subset simultaneously.\n",
        "\n",
        "```python\n",
        "from multiprocessing import Process\n",
        "\n",
        "def square_numbers(numbers):\n",
        "    return [n * n for n in numbers]\n",
        "\n",
        "# Define data and processes\n",
        "data = [10, 20, 30, 40, 50]\n",
        "processes = [Process(target=square_numbers, args=(data[i:i+2],)) for i in range(0, len(data), 2)]\n",
        "\n",
        "# Start and join each process\n",
        "for p in processes:\n",
        "    p.start()\n",
        "for p in processes:\n",
        "    p.join()\n",
        "```\n",
        "\n",
        "### In Summary\n",
        "Multiprocessing is used in Python to leverage multi-core CPUs for concurrent execution, enabling programs to perform CPU-bound tasks more efficiently while circumventing Pythonâ€™s GIL. Itâ€™s ideal for tasks that need parallelism, isolation, or efficient management of complex workloads."
      ],
      "metadata": {
        "id": "5obYXpNvMv9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock.\n",
        "\n"
      ],
      "metadata": {
        "id": "_Iq5aUHcNKdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared resource\n",
        "numbers = []\n",
        "# Lock to avoid race conditions\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function for adding numbers to the list\n",
        "def add_numbers():\n",
        "    for i in range(5):\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate delay\n",
        "        lock.acquire()  # Acquire lock before modifying the list\n",
        "        num = random.randint(1, 100)\n",
        "        numbers.append(num)\n",
        "        print(f\"Added: {num}\")\n",
        "        lock.release()  # Release lock after modification\n",
        "\n",
        "# Function for removing numbers from the list\n",
        "def remove_numbers():\n",
        "    for i in range(5):\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate delay\n",
        "        lock.acquire()  # Acquire lock before modifying the list\n",
        "        if numbers:\n",
        "            num = numbers.pop(0)\n",
        "            print(f\"Removed: {num}\")\n",
        "        else:\n",
        "            print(\"List is empty, nothing to remove.\")\n",
        "        lock.release()  # Release lock after modification\n",
        "\n",
        "# Create threads\n",
        "adder_thread = threading.Thread(target=add_numbers)\n",
        "remover_thread = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Start threads\n",
        "adder_thread.start()\n",
        "remover_thread.start()\n",
        "\n",
        "# Wait for both threads to complete\n",
        "adder_thread.join()\n",
        "remover_thread.join()\n",
        "\n",
        "print(\"Final list:\", numbers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iOlMA5nNUaq",
        "outputId": "8b4db676-aec3-4031-d064-a8bd67b597dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added: 8\n",
            "Removed: 8\n",
            "Added: 100\n",
            "Removed: 100\n",
            "List is empty, nothing to remove.\n",
            "List is empty, nothing to remove.\n",
            "Added: 64\n",
            "Added: 57\n",
            "Removed: 64\n",
            "Added: 43\n",
            "Final list: [57, 43]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Describe the methods and tools available in Python for safely sharing data between threads and processes.\n",
        "**Ans:-** Python provides various methods and tools to safely share data between threads and processes. These tools help synchronize data access, preventing race conditions, and ensuring data consistency.\n",
        "\n",
        "### 1. **For Threads (Using `threading` Module)**\n",
        "\n",
        "- **Locks (`threading.Lock`)**:\n",
        "  - `Lock` is a basic synchronization primitive used to prevent race conditions by allowing only one thread to access a shared resource at a time.\n",
        "  - A lock is acquired before accessing the shared data and released afterward.\n",
        "\n",
        "  ```python\n",
        "  import threading\n",
        "\n",
        "  lock = threading.Lock()\n",
        "\n",
        "  def thread_safe_function():\n",
        "      lock.acquire()\n",
        "      # Access shared resource\n",
        "      lock.release()\n",
        "  ```\n",
        "\n",
        "- **RLocks (`threading.RLock`)**:\n",
        "  - `RLock` (reentrant lock) allows a thread to acquire the same lock multiple times without causing a deadlock. This is useful if a thread needs to re-enter a locked block of code.\n",
        "\n",
        "  ```python\n",
        "  lock = threading.RLock()\n",
        "  ```\n",
        "\n",
        "- **Condition (`threading.Condition`)**:\n",
        "  - Conditions let threads wait for certain conditions to become true. Itâ€™s often used for complex synchronization tasks where a thread needs to wait until another thread changes the state of shared data.\n",
        "\n",
        "  ```python\n",
        "  condition = threading.Condition()\n",
        "\n",
        "  def thread_with_condition():\n",
        "      with condition:\n",
        "          condition.wait()  # Wait for condition to be met\n",
        "          # Access shared data\n",
        "          condition.notify()  # Notify other threads\n",
        "  ```\n",
        "\n",
        "- **Queues (`queue.Queue`)**:\n",
        "  - `Queue` is thread-safe and often used to pass data between threads. It manages access internally with locks, allowing multiple threads to put and get items without explicit locking.\n",
        "\n",
        "  ```python\n",
        "  import queue\n",
        "\n",
        "  q = queue.Queue()\n",
        "\n",
        "  def producer():\n",
        "      q.put(\"data\")\n",
        "\n",
        "  def consumer():\n",
        "      data = q.get()\n",
        "  ```\n",
        "\n",
        "### 2. **For Processes (Using `multiprocessing` Module)**\n",
        "\n",
        "- **Queues (`multiprocessing.Queue`)**:\n",
        "  - `multiprocessing.Queue` enables safe data sharing between processes by using internal locks and managing memory in a way that allows data to be shared across process boundaries.\n",
        "  - It can hold data types that can be serialized (pickled), allowing inter-process communication (IPC).\n",
        "\n",
        "  ```python\n",
        "  from multiprocessing import Queue, Process\n",
        "\n",
        "  q = Queue()\n",
        "\n",
        "  def producer():\n",
        "      q.put(\"data\")\n",
        "\n",
        "  def consumer():\n",
        "      data = q.get()\n",
        "  ```\n",
        "\n",
        "- **Pipes (`multiprocessing.Pipe`)**:\n",
        "  - `Pipe` creates a pair of connection objects for two-way communication between processes. Itâ€™s more direct than a queue but is usually limited to two processes.\n",
        "\n",
        "  ```python\n",
        "  from multiprocessing import Pipe\n",
        "\n",
        "  conn1, conn2 = Pipe()\n",
        "\n",
        "  def send_data():\n",
        "      conn1.send(\"Hello\")\n",
        "\n",
        "  def receive_data():\n",
        "      data = conn2.recv()\n",
        "  ```\n",
        "\n",
        "- **Shared Memory Objects (`Value` and `Array`)**:\n",
        "  - **`multiprocessing.Value`**: A shared memory variable for a single value, which can be accessed and modified by multiple processes.\n",
        "  - **`multiprocessing.Array`**: A shared array of values. Both `Value` and `Array` are synchronized by default and can store basic data types.\n",
        "\n",
        "  ```python\n",
        "  from multiprocessing import Value, Array\n",
        "\n",
        "  shared_value = Value('i', 0)\n",
        "  shared_array = Array('i', [1, 2, 3])\n",
        "  ```\n",
        "\n",
        "- **Managers (`multiprocessing.Manager`)**:\n",
        "  - Managers provide a way to create shared data structures such as lists, dictionaries, and other collections, which can be safely accessed by multiple processes.\n",
        "  - Itâ€™s useful when you need to share complex data structures between processes.\n",
        "\n",
        "  ```python\n",
        "  from multiprocessing import Manager\n",
        "\n",
        "  manager = Manager()\n",
        "  shared_dict = manager.dict()\n",
        "  shared_list = manager.list()\n",
        "  ```\n",
        "\n",
        "### 3. **Synchronization Primitives for Processes**\n",
        "\n",
        "- **Locks (`multiprocessing.Lock`)**:\n",
        "  - Similar to `threading.Lock`, but specifically designed for inter-process synchronization.\n",
        "\n",
        "  ```python\n",
        "  from multiprocessing import Lock\n",
        "\n",
        "  lock = Lock()\n",
        "  ```\n",
        "\n",
        "- **Events (`multiprocessing.Event`)**:\n",
        "  - An `Event` can be used to signal between processes. One process sets the event, and others can wait for it to be set.\n",
        "\n",
        "  ```python\n",
        "  from multiprocessing import Event\n",
        "\n",
        "  event = Event()\n",
        "\n",
        "  def wait_for_event():\n",
        "      event.wait()\n",
        "      # Proceed after event is set\n",
        "  ```\n",
        "\n",
        "- **Conditions (`multiprocessing.Condition`)**:\n",
        "  - Allows processes to wait for certain conditions to be met, similar to `threading.Condition`.\n",
        "\n",
        "### Summary Table\n",
        "\n",
        "| Tool                | For Threads | For Processes | Purpose                         |\n",
        "|---------------------|-------------|---------------|---------------------------------|\n",
        "| `Lock`              | âœ…          | âœ…            | Ensures exclusive access        |\n",
        "| `RLock`             | âœ…          | ðŸš«            | Reentrant lock for threads      |\n",
        "| `Condition`         | âœ…          | âœ…            | Complex synchronization         |\n",
        "| `Queue`             | âœ…          | âœ…            | Thread/process-safe data queue  |\n",
        "| `Pipe`              | ðŸš«          | âœ…            | Two-way communication channel   |\n",
        "| `Value` / `Array`   | ðŸš«          | âœ…            | Shared memory for basic types   |\n",
        "| `Manager`           | ðŸš«          | âœ…            | Shared complex data structures  |\n",
        "| `Event`             | ðŸš«          | âœ…            | Process signaling               |\n",
        "\n",
        "### Conclusion\n",
        "In Python, threads and processes have different mechanisms for safely sharing data. While threads can directly share memory but need locking, processes have isolated memory spaces and rely on IPC techniques like queues, pipes, shared memory objects, and managers to share data safely across boundaries."
      ],
      "metadata": {
        "id": "3KL0PyyzNnOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Discuss why itâ€™s crucial to handle exceptions in concurrent programs and the techniques available for doing so.\n",
        "**Ans:-** Handling exceptions in concurrent programs is crucial because these programs run multiple tasks simultaneously, and failures in one thread or process can lead to unpredictable behavior, resource leaks, or even crashes in the main program. Without proper error handling, an exception in a concurrent task might go unnoticed, making it harder to debug, recover, or ensure that all tasks complete correctly.\n",
        "\n",
        "### Reasons for Exception Handling in Concurrent Programs\n",
        "\n",
        "1. **Ensuring Program Stability**:\n",
        "   - An unhandled exception in one thread or process can halt the entire program or cause data corruption if not managed properly.\n",
        "   \n",
        "2. **Graceful Error Recovery**:\n",
        "   - In applications requiring high availability, managing exceptions allows a program to handle failures gracefully, log them, and possibly restart failed tasks.\n",
        "\n",
        "3. **Resource Management**:\n",
        "   - In concurrency, resource handling (like file handles, network connections, or database sessions) is critical. Exceptions, if not handled, can lead to resource leaks by not releasing or cleaning up properly.\n",
        "\n",
        "4. **Debugging and Logging**:\n",
        "   - Unhandled exceptions in background threads can be silent, making it difficult to identify the root cause of failures. Catching exceptions allows logging and easier debugging.\n",
        "\n",
        "### Techniques for Exception Handling in Concurrent Programs\n",
        "\n",
        "#### 1. **Try-Except Blocks Around Task Code**\n",
        "   - Wrapping code in `try-except` blocks within each thread or process ensures that exceptions are captured and managed locally.\n",
        "   - This is the most straightforward approach and works well for non-critical exceptions or tasks that can continue independently.\n",
        "\n",
        "   ```python\n",
        "   import threading\n",
        "\n",
        "   def task():\n",
        "       try:\n",
        "           # Task code that might raise an exception\n",
        "           pass\n",
        "       except Exception as e:\n",
        "           print(f\"Exception in thread: {e}\")\n",
        "\n",
        "   t = threading.Thread(target=task)\n",
        "   t.start()\n",
        "   ```\n",
        "\n",
        "#### 2. **Returning Exception Details via `concurrent.futures`**\n",
        "   - The `concurrent.futures` module (for both threads and processes) allows tasks to return results or raise exceptions. When using `Future` objects, exceptions can be handled after a task completes by checking the `.exception()` method or handling exceptions raised by `.result()`.\n",
        "\n",
        "   ```python\n",
        "   from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "   def task():\n",
        "       # Simulate error\n",
        "       raise ValueError(\"Something went wrong\")\n",
        "\n",
        "   with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "       future = executor.submit(task)\n",
        "       try:\n",
        "           result = future.result()  # This will raise the exception\n",
        "       except Exception as e:\n",
        "           print(f\"Handled exception: {e}\")\n",
        "   ```\n",
        "\n",
        "#### 3. **Exception Handling in `multiprocessing.Pool`**\n",
        "   - In `multiprocessing.Pool`, exceptions are returned when tasks are completed via methods like `apply_async()`, `map_async()`, or `get()`.\n",
        "   - This approach ensures exceptions are caught at the main thread and can be handled outside of the worker process.\n",
        "\n",
        "   ```python\n",
        "   from multiprocessing import Pool\n",
        "\n",
        "   def task(x):\n",
        "       if x == 2:\n",
        "           raise ValueError(\"Intentional Error!\")\n",
        "       return x * x\n",
        "\n",
        "   with Pool(4) as pool:\n",
        "       try:\n",
        "           results = pool.map(task, [1, 2, 3])  # Exception will propagate\n",
        "       except Exception as e:\n",
        "           print(f\"Handled exception: {e}\")\n",
        "   ```\n",
        "\n",
        "#### 4. **Using Custom Error Callbacks in Asynchronous Execution**\n",
        "   - In asynchronous operations (like with `apply_async` in `multiprocessing`), a custom callback function can handle exceptions, logging or performing cleanup when a task fails.\n",
        "\n",
        "   ```python\n",
        "   from multiprocessing import Pool\n",
        "\n",
        "   def task(x):\n",
        "       if x == 2:\n",
        "           raise ValueError(\"Error in task!\")\n",
        "       return x * x\n",
        "\n",
        "   def handle_error(error):\n",
        "       print(f\"Error: {error}\")\n",
        "\n",
        "   with Pool(4) as pool:\n",
        "       for i in range(5):\n",
        "           pool.apply_async(task, args=(i,), error_callback=handle_error)\n",
        "       pool.close()\n",
        "       pool.join()\n",
        "   ```\n",
        "\n",
        "#### 5. **Thread/Process Termination and Restart Mechanisms**\n",
        "   - In cases where tasks are critical and need to be retried, you can handle exceptions by restarting threads or processes, using a supervisory thread or process manager to detect failed tasks and restart them as needed.\n",
        "   \n",
        "#### 6. **Logging and Monitoring Tools**\n",
        "   - Using logging within exception handling blocks enables tracking errors for debugging and auditing purposes. External monitoring tools, like Sentry or New Relic, can also catch and report exceptions for analysis.\n",
        "\n",
        "#### 7. **Graceful Shutdown with Cleanup**\n",
        "   - Using `finally` blocks or context managers ensures that resources are released correctly, even if an exception occurs. For instance, if threads/processes need to release resources upon failure, a `finally` block can be used to guarantee cleanup actions.\n",
        "\n",
        "   ```python\n",
        "   import threading\n",
        "\n",
        "   def task():\n",
        "       try:\n",
        "           # Perform task\n",
        "           pass\n",
        "       except Exception as e:\n",
        "           print(f\"Exception in thread: {e}\")\n",
        "       finally:\n",
        "           print(\"Cleaning up resources\")\n",
        "\n",
        "   t = threading.Thread(target=task)\n",
        "   t.start()\n",
        "   ```\n",
        "\n",
        "### Summary Table of Techniques\n",
        "\n",
        "| Technique                                     | Use Case                               |\n",
        "|-----------------------------------------------|----------------------------------------|\n",
        "| `try-except` in threads/processes             | Simple error management in tasks       |\n",
        "| `concurrent.futures` exception handling       | Thread/Process pools with `Future` objects |\n",
        "| Exception handling in `multiprocessing.Pool`  | Capturing errors in process pools      |\n",
        "| Custom error callbacks                        | Handling async errors in `apply_async` |\n",
        "| Restarting failed threads/processes           | Critical tasks needing retries         |\n",
        "| Logging and monitoring                        | Debugging and external monitoring      |\n",
        "| `finally` for resource cleanup                | Releasing resources upon failure       |\n",
        "\n",
        "### Conclusion\n",
        "Properly handling exceptions in concurrent programs is critical to maintain stability, recover from failures, and avoid resource leaks. Techniques like local `try-except` blocks, `concurrent.futures`, custom callbacks, logging, and cleanup mechanisms all help ensure that exceptions are managed effectively in multithreaded and multiprocessed environments.\n"
      ],
      "metadata": {
        "id": "UdL_65TSN13z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
        "**Ans:-** Here's a Python program that uses `concurrent.futures.ThreadPoolExecutor` to calculate the factorial of numbers from 1 to 10 concurrently. Each factorial calculation runs in a separate thread within a thread pool, and results are printed as they are computed.\n",
        "\n",
        "```python\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Function to calculate factorial\n",
        "def factorial(n):\n",
        "    result = 1\n",
        "    for i in range(1, n + 1):\n",
        "        result *= i\n",
        "    return f\"Factorial of {n} is {result}\"\n",
        "\n",
        "# List of numbers to calculate factorials for\n",
        "numbers = list(range(1, 11))\n",
        "\n",
        "# Using ThreadPoolExecutor to manage threads\n",
        "with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "    # Submit tasks to the thread pool\n",
        "    futures = [executor.submit(factorial, number) for number in numbers]\n",
        "\n",
        "    # Print results as they complete\n",
        "    for future in as_completed(futures):\n",
        "        print(future.result())\n",
        "```\n",
        "\n",
        "### Explanation\n",
        "1. **factorial(n)**: A function that calculates the factorial of a given number `n`.\n",
        "2. **ThreadPoolExecutor**: We create a `ThreadPoolExecutor` with a maximum of 5 threads. This controls the number of concurrent threads.\n",
        "3. **Submitting tasks**: The `factorial` function is submitted as a task for each number from 1 to 10. Each task is managed by the thread pool.\n",
        "4. **Collecting results**: Using `as_completed`, we retrieve and print the results as each thread completes.\n",
        "\n",
        "### Output\n",
        "The output will display factorials in the order each calculation finishes, which may vary because tasks run concurrently.\n",
        "\n",
        "### Sample Output\n",
        "```\n",
        "Factorial of 4 is 24\n",
        "Factorial of 6 is 720\n",
        "Factorial of 3 is 6\n",
        "Factorial of 2 is 2\n",
        "Factorial of 5 is 120\n",
        "Factorial of 9 is 362880\n",
        "Factorial of 8 is 40320\n",
        "Factorial of 1 is 1\n",
        "Factorial of 7 is 5040\n",
        "Factorial of 10 is 3628800\n",
        "```\n",
        "\n",
        "Each factorial calculation runs in parallel, demonstrating concurrent execution.\n"
      ],
      "metadata": {
        "id": "7WyFmA02Od9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes).\n",
        "\n"
      ],
      "metadata": {
        "id": "86rBuV7ZPHb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Function to calculate square of a number\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# Function to compute squares in parallel and measure time\n",
        "def compute_squares_with_pool(pool_size):\n",
        "    numbers = list(range(1, 11))\n",
        "    with Pool(pool_size) as pool:\n",
        "        start_time = time.time()\n",
        "        results = pool.map(square, numbers)\n",
        "        end_time = time.time()\n",
        "    return results, end_time - start_time\n",
        "\n",
        "# Test the computation with different pool sizes\n",
        "for pool_size in [2, 4, 8]:\n",
        "    results, time_taken = compute_squares_with_pool(pool_size)\n",
        "    print(f\"Pool size: {pool_size}\")\n",
        "    print(f\"Results: {results}\")\n",
        "    print(f\"Time taken: {time_taken:.4f} seconds\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NKyuqNwPcgU",
        "outputId": "aa6d12f2-36eb-4691-8baa-3a59d14da7d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size: 2\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0082 seconds\n",
            "\n",
            "Pool size: 4\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0101 seconds\n",
            "\n",
            "Pool size: 8\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0120 seconds\n",
            "\n"
          ]
        }
      ]
    }
  ]
}